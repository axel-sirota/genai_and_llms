{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzf37X_XizQQ"
   },
   "source": [
    "# Transformers\n",
    "\n",
    "© Data Trainers LLC. GPL v 3.0.\n",
    "\n",
    "Author: Axel Sirota\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Inspired highly on the tutorial [NMT with Transformers](https://www.tensorflow.org/text/tutorials/transformer) which takes the code from the original Transformer model paper originally proposed in [\"Attention is all you need\"](https://arxiv.org/abs/1706.03762) by Vaswani et al. (2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovyaAhLpa55P"
   },
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19312,
     "status": "ok",
     "timestamp": 1695614235752,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "C9BTEOu0PerV",
    "outputId": "22013df3-ae56-46cb-af8f-e61a17a1fe4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
      "Collecting gensim==4.2.0\n",
      "  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m24.0/24.0 MB\u001B[0m \u001B[31m35.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting keras-nlp\n",
      "  Downloading keras_nlp-0.6.2-py3-none-any.whl (590 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m590.1/590.1 kB\u001B[0m \u001B[31m28.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting keras-preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.6/42.6 kB\u001B[0m \u001B[31m4.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting tensorflow-text>=2.11\n",
      "  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.5/6.5 MB\u001B[0m \u001B[31m70.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.23.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (1.11.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.2.0) (6.4.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
      "Collecting keras-core (from keras-nlp)\n",
      "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m950.8/950.8 kB\u001B[0m \u001B[31m57.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (23.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.5.2)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-preprocessing) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text>=2.11) (0.14.0)\n",
      "Requirement already satisfied: tensorflow<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (1.57.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.9.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (67.7.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.33.0)\n",
      "Collecting namex (from keras-core->keras-nlp)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.41.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.3.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<2.14,>=2.13.0->tensorflow-text>=2.11) (3.2.2)\n",
      "Installing collected packages: namex, keras-preprocessing, gensim, keras-core, tensorflow-text, keras-nlp\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 4.3.2\n",
      "    Uninstalling gensim-4.3.2:\n",
      "      Successfully uninstalled gensim-4.3.2\n",
      "Successfully installed gensim-4.2.0 keras-core-0.1.7 keras-nlp-0.6.2 keras-preprocessing-1.1.2 namex-0.0.7 tensorflow-text-2.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U nltk 'tensorflow-text==2.15.0' 'keras-nlp' 'keras-preprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1695614235754,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "wSaLeBcpqiT5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8962,
     "status": "ok",
     "timestamp": 1695614244706,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "0fpgYwAtNO2T",
    "outputId": "da83f8de-1b15-4f42-de93-7ba367c137e4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import preprocessing\n",
    "from textblob import TextBlob, Word\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import Model, Input\n",
    "import tensorflow_text as tf_text\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import warnings\n",
    "import nltk\n",
    "import time\n",
    "\n",
    "TRACE = False\n",
    "\n",
    "def set_seeds_and_trace():\n",
    "  os.environ['PYTHONHASHSEED'] = '0'\n",
    "  np.random.seed(42)\n",
    "  tf.random.set_seed(42)\n",
    "  random.seed(42)\n",
    "  if TRACE:\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "def set_session_with_gpus_and_cores():\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "  sess = tf.compat.v1.Session(config=config)\n",
    "  tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "set_seeds_and_trace()\n",
    "set_session_with_gpus_and_cores()\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekM1n0-JdYPN"
   },
   "source": [
    "## The Transformer Layers\n",
    "\n",
    "In this demo we will create, from scratch, with the same tools the original Authors had, the Transformer architecture. Why? To understand how it works, why it works, and exactly what is novel!\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The original Transformer diagram</th>\n",
    "  <th colspan=1>A representation of a 4-layer Transformer</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
    "  </td>\n",
    "  <td>\n",
    "   <img width=307 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-4layer-compact.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Each of the components in these two diagrams will be explained as you progress through the demo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFbNft2shTPp"
   },
   "source": [
    "### What did we have before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2FoDkeGhWJk"
   },
   "source": [
    "Before, we used Cross Attention or self attention, remember? And for sequence data we basically used it like this:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>Seq2Seq with attention</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.dropbox.com/s/r6u7ll5nlt96t9f/seq2seq.png?raw=1\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3huYRrUjCAI"
   },
   "source": [
    "Where we input attention with the hidden state to create another updated hidden state we could input into the next cell. And this worked well on medium sized sentences, but was hard to train and unstable. Now that we know this, the Transformer basicaly tried to get rid of the RNN by using **only** attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwmp1jC0dxVJ"
   },
   "source": [
    "### The embedding and positional encoding layer\n",
    "\n",
    "The inputs to both the encoder and decoder use the same embedding and positional encoding logic.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The embedding and positional encoding layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/PositionalEmbedding.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1695614244707,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "UkI09F6zdXnb"
   },
   "outputs": [],
   "source": [
    "## This comes straight from the paper\n",
    "\n",
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "\n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1)\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1695614244708,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "gLC8RPIkd--M"
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True)\n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1695614245211,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "GAnc5AKSeOvn"
   },
   "outputs": [],
   "source": [
    "pos = PositionalEmbedding(5000, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1695614245211,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "zlIZmHLMemkR",
    "outputId": "3318916e-937f-421a-8e89-5ddda230f341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tf.constant(np.random.randint(1,5000, size=(3,26)))\n",
    "response = pos(input)\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1695614245212,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "XnIEkVWqg59O",
    "outputId": "76beea4f-d0df-4dc3-cb2a-8123322f45d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 26), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response._keras_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvlTAaqqhTBo"
   },
   "source": [
    "### Add and normalize\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=2>Add and normalize</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Add+Norm.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-ZTlyygheuT"
   },
   "source": [
    "Note: Use `Add` layer instead of + to propagate masks\n",
    "\n",
    "We will create a BaseAttention layer that inherits the Add+Norm and then each subclass of attention will implement the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1695614245213,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "OMMyVtc6hLaM"
   },
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5Toc-Uukh15"
   },
   "source": [
    "### Self Attention layer\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The global self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/SelfAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1695614245213,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "RP4L1Mn-iFCl"
   },
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    # We need to compare everything with everything, therefore Q, K and V must be the input\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])  # This one comes from the base class\n",
    "    x = self.layernorm(x)  # This one comes from the base class\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "316Iwonjm6JY"
   },
   "source": [
    "Let's test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 730,
     "status": "ok",
     "timestamp": 1695614245934,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "goX_DO0Sk8UB",
    "outputId": "5ef09fb9-b148-43c5-c3e9-209fce26e18d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "\n",
    "# First we apply the PositionalEmbedding to embed into what the attention layer expects\n",
    "pos = PositionalEmbedding(vocab_size, embedding_dim)\n",
    "\n",
    "# Then we do the self attention, the n_heads is arbitrary\n",
    "gsa = GlobalSelfAttention(num_heads=3, key_dim=embedding_dim)\n",
    "\n",
    "\n",
    "response = gsa(pos(input))\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5lGk8ZMle7K"
   },
   "source": [
    "Notice the shape is the same, since MHA concats all 3 heads and the we add everything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J76TA2ZMlrke"
   },
   "source": [
    "### The cross attention layer\n",
    "\n",
    "This layer connects the encoder and decoder. This layer is the most straight-forward use of attention in the model, it performs the same task as the attention block in the previous demo (and we will copy it).\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The cross attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1695614245934,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "OxZMLVBRlMPz"
   },
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,  # This is the key part!!\n",
    "        value=context,  # This is the key part!!\n",
    "        return_attention_scores=True)\n",
    "\n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1695614246657,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "R9v9MPbvmVJw",
    "outputId": "1224232b-d5aa-4636-f93b-aaa54397d523"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "\n",
    "pos_es = PositionalEmbedding(vocab_size_es, embedding_dim_es)\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "\n",
    "gsa = GlobalSelfAttention(num_heads=3, key_dim=embedding_dim_es)\n",
    "cross = CrossAttention(num_heads=3, key_dim=embedding_dim_en)\n",
    "\n",
    "\n",
    "context = gsa(pos_es(input_es)) # Forget about the feed forwards\n",
    "\n",
    "response = cross(pos_en(input_en), context=context) # Forget about masked attention for now, assume it is the identity\n",
    "\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5bXoAwvoD8T"
   },
   "source": [
    "Notice the shape is (batch_size, words in sentence in output, embedding_dim) , regardless the input sentence had more words or other embedding dim. We are doing a good move forward!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuNqXT82oaRo"
   },
   "source": [
    "### The causal self attention layer (Masked Multi Headed Attention)\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The causal self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-jDIHkJowAP"
   },
   "source": [
    "The only big difference in the masked multi headedd attention is that we cannot attend to words in the future, so we will use a mask such that the `Nth` word can only see the first `N-1` words and not all the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1695614246658,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "z6N9U3qvn9Ui"
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)  # This is the key!\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PgCBG1b-osuv"
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The causal self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=330 src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention-new-full.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdE_KY2TpEPC"
   },
   "source": [
    "Notice in the diagram above how the query can onlly attend the values for the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1695614246659,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "RaHIa0k4oqD1",
    "outputId": "e4f7cae3-3fa9-46dd-c984-30cd043b9db9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "csa = CausalSelfAttention(num_heads =3, key_dim=embedding_dim_en)\n",
    "\n",
    "response = csa(pos_es(input_en))\n",
    "\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8_jJCg8pE6b"
   },
   "source": [
    "### The feed forward network\n",
    "\n",
    "The transformer also includes this point-wise feed-forward network in both the encoder and decoder:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The feed forward network</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/FeedForward.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1695614246659,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "Wu5xFoRjpBty"
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Pm7uGPMpqwu"
   },
   "source": [
    "### The encoder layer\n",
    "\n",
    "The encoder contains a stack of `N` encoder layers. Where each `EncoderLayer` contains a `GlobalSelfAttention` and `FeedForward` layer:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The encoder layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/EncoderLayer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1695614246659,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "3SJl4aJ_pSR0"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 387,
     "status": "ok",
     "timestamp": 1695614247040,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "4NUNWld5uOBo",
    "outputId": "90e130ef-d0a7-42c8-de22-4d4bf33ba084"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "pos = PositionalEmbedding(vocab_size, embedding_dim)\n",
    "sample_encoder_layer = EncoderLayer(d_model=embedding_dim, num_heads=3, dff=1012)\n",
    "response = sample_encoder_layer(pos(input))\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MzC1z-vuuxF"
   },
   "source": [
    "### The encoder\n",
    "\n",
    "Notice we need to be able to repeat the past EncoderLayer Nx times, so we need another Layer that is able to do exactly that\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The encoder</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Encoder.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1695614247041,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "0TlZP_vVulm0"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "\n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1695614247379,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "Yf9wGOSMwaEt",
    "outputId": "f66a4231-2903-42a7-e20a-70e5899a5d96"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 26, 100])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size = 5000\n",
    "input = tf.constant(np.random.randint(1,vocab_size, size=(3,26)))\n",
    "sample_encoder = Encoder(num_layers=4,\n",
    "                         d_model=embedding_dim,\n",
    "                         num_heads=3,\n",
    "                         dff=512,\n",
    "                         vocab_size=vocab_size)\n",
    "response = sample_encoder(input)\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUU9CG_MwtJC"
   },
   "source": [
    "We got our Encoder!! Yahoo!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UR4MuroWw4p-"
   },
   "source": [
    "### The decoder layer\n",
    "\n",
    "Same as before we need a Decoder layer that uses the Attention layers and then another layer to permit having Nx layers of decoding\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The decoder layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/DecoderLayer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1695614247380,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "_v5voBr2wywC"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1695614248445,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "aP3yjQeuy2n4",
    "outputId": "6db56685-0325-4305-b5e9-fa1ae7909a45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "pos_en = PositionalEmbedding(vocab_size_en, embedding_dim_en)\n",
    "\n",
    "\n",
    "encoder =  Encoder(num_layers=2, d_model=embedding_dim_es, num_heads=3, dff=512, vocab_size=vocab_size_es)\n",
    "\n",
    "context = encoder(input_es)\n",
    "\n",
    "decoder_layer = DecoderLayer(d_model=embedding_dim_en, num_heads=3, dff=218, dropout_rate=0.2)\n",
    "\n",
    "response = decoder_layer(pos_en(input_en), context=context)\n",
    "\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pog5S-gQz9nF"
   },
   "source": [
    "### The Decoder\n",
    "\n",
    "Similar to the `Encoder`, the `Decoder` consists of a `PositionalEmbedding`, and a stack of `DecoderLayer`s:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The embedding and positional encoding layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Decoder.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1695614248446,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "dEZ2-NRbz1jz"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1173,
     "status": "ok",
     "timestamp": 1695614249612,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "Mp4zkTw22-23",
    "outputId": "bc976268-d63e-42cf-ab71-b0a0ef658b37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim_es = 100\n",
    "vocab_size_es = 5000\n",
    "\n",
    "embedding_dim_en = 512\n",
    "vocab_size_en = 6000\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "encoder =  Encoder(num_layers=2, d_model=embedding_dim_es, num_heads=3, dff=512, vocab_size=vocab_size_es)\n",
    "\n",
    "context = encoder(input_es)\n",
    "\n",
    "decoder = Decoder(num_layers=3, d_model=embedding_dim_en, num_heads=5, dff=124, vocab_size=vocab_size_en)\n",
    "\n",
    "response = decoder(input_en, context=context)\n",
    "\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3r2JLfz04Hsc"
   },
   "source": [
    "## The Transformer Model\n",
    "\n",
    "You now have `Encoder` and `Decoder`. To complete the `Transformer` model, you need to put them together and add a final linear (`Dense`) layer which converts the resulting vector at each location into output token probabilities.\n",
    "\n",
    "The output of the decoder is the input to this final linear layer.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The transformer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1695614249613,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "VrXSLwrF36u_"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1856,
     "status": "ok",
     "timestamp": 1695614251460,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "7CIxbfVx9IBc",
    "outputId": "b5006d19-e999-41ec-f909-b2b19c4d3870"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 24, 6000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "vocab_size_es = 5000\n",
    "vocab_size_en = 6000\n",
    "\n",
    "num_layers = 4\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# We are supposing the model will translate Spanish to English, so context for CrossAttention will be the spanish input.\n",
    "\n",
    "input_es = tf.constant(np.random.randint(1,vocab_size_es, size=(3,26)))\n",
    "input_en = tf.constant(np.random.randint(1,vocab_size_es, size=(3,24)))\n",
    "\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=embedding_dim,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=vocab_size_es,\n",
    "    target_vocab_size=vocab_size_en,\n",
    "    dropout_rate=dropout_rate)\n",
    "\n",
    "response = transformer((input_es, input_en))\n",
    "response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1695614251990,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "Gy5B7d_E-NDE",
    "outputId": "4448e8bb-7362-482e-e056-4b5cc0d42bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_3 (Encoder)         multiple                  2203648   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  3594448   \n",
      "                                                                 \n",
      " dense_42 (Dense)            multiple                  606000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6404096 (24.43 MB)\n",
      "Trainable params: 6404096 (24.43 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1695614251991,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "VqnWfvyM7XDJ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJjI6PJYJ3HU2ZPWkTHiJV",
   "provenance": [
    {
     "file_id": "1otwsOo2cwEwpxH1qabt517MH75K2NmzE",
     "timestamp": 1695614167191
    },
    {
     "file_id": "1n9cfGE0sI6sHfOzsAQhZOR8afPIqgCO6",
     "timestamp": 1695269303209
    },
    {
     "file_id": "1I0KA4wCjVa0s9YZsLkAX6JaN-bAdLUlb",
     "timestamp": 1695269238458
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}