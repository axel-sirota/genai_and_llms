{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r45tbR6lkYEa"
   },
   "source": [
    "# Attention with Keras\n",
    "\n",
    "Â© Data Trainers LLC. GPL v 3.0.\n",
    "\n",
    "Author: Axel Sirota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcU-PBR3kbaL"
   },
   "source": [
    "A whole new world opportunities appear when considering using the layer implementations of the attention components. As of July 2023 we have 3 layers implemented:\n",
    "\n",
    "- AdditiveAttention: This is the original Attention from the Bahdanau paper that incorporates the concept of Q,K,V attention we say in demo 2; setting, in this case, K=V.\n",
    "- Attention: This is the Dot Product attention from *Luong et. al.* we saw in the first demo.\n",
    "- MultiHeadAttention: The general attention everyone uses and we will learn in this demo! It is basically many layers of self attention.\n",
    "\n",
    "Let's get to it!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JsTW2QHimUlx"
   },
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16559,
     "status": "ok",
     "timestamp": 1695612123126,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "C9BTEOu0PerV",
    "outputId": "9fc3667d-3303-4e50-ac06-2d4b02dbb147"
   },
   "outputs": [],
   "source": "!pip install -U nltk gensim 'numpy<2' 'tensorflow-text==2.15.0' 'keras-nlp' 'keras-preprocessing'"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H2IYs8QkXZd"
   },
   "source": [
    "Let's run some helper functions to setup using the GPUs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11179,
     "status": "ok",
     "timestamp": 1695612134291,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "0fpgYwAtNO2T",
    "outputId": "d81f8e9d-c21a-4d49-8c3e-b265439c88c3"
   },
   "outputs": [],
   "source": "import multiprocessing\nimport tensorflow as tf\nimport sys\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, Lambda, ELU, Conv1D, MaxPooling1D, Dropout\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom sklearn.model_selection import train_test_split\nfrom keras import preprocessing\nfrom textblob import TextBlob, Word\nfrom keras_preprocessing.sequence import pad_sequences\nfrom keras.initializers import Constant\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import Model, Input\nimport numpy as np\nimport re\nimport random\nimport os\nimport pandas as pd\nimport gensim\nimport warnings\nimport nltk\nimport time\n\nTRACE = False\n\ndef set_seeds_and_trace():\n  os.environ['PYTHONHASHSEED'] = '0'\n  np.random.seed(42)\n  tf.random.set_seed(42)\n  random.seed(42)\n  if TRACE:\n    tf.debugging.set_log_device_placement(True)\n\ndef set_session_with_gpus_and_cores():\n  cores = multiprocessing.cpu_count()\n  gpus = len(tf.config.list_physical_devices('GPU'))\n  config = tf.compat.v1.ConfigProto( device_count = {'GPU': gpus  , 'CPU': cores} , intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n  sess = tf.compat.v1.Session(config=config)\n  tf.compat.v1.keras.backend.set_session(sess)\n\nset_seeds_and_trace()\nset_session_with_gpus_and_cores()\nwarnings.filterwarnings('ignore')\nnltk.download('punkt')"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvVC_dlqmdf6"
   },
   "source": [
    "## Attention *a la Bahdanau*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibxTc61LmmhK"
   },
   "source": [
    "The easiest way to test a Layer in Keras is to create a simple model that uses such a layer, we will do just that! This also shows how easy is to add attention to your models, which we will use extensively when creating THE Transformer from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLbdmNwEoUM7"
   },
   "source": [
    "Notice we need a custom model class because the inputs needs to be the query and value, and they could have different embeddings as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1695612134293,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "36P0ESmxThvQ"
   },
   "outputs": [],
   "source": [
    "class AttentionModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, vocab_size, max_tokens, embedding_dim, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_tokens)\n",
    "    self.attention = tf.keras.layers.AdditiveAttention()\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "\n",
    "    query, value = inputs\n",
    "    # Query embeddings of shape [batch_size, Tq, dimension].\n",
    "    query_embeddings = self.embedding(query)\n",
    "    # Value embeddings of shape [batch_size, Tv, dimension].\n",
    "    value_embeddings = self.embedding(value)\n",
    "    # Notice we could have an embedding for the inputs and another embedding for outputs, we will see more of that later\n",
    "    x = self.attention([query_embeddings, value_embeddings])\n",
    "    x = self.dropout(x, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "    return x\n",
    "\n",
    "  def build_graph(self, max_tokens, embedding_dim):\n",
    "    query_input = tf.keras.Input(shape=(None, max_tokens, embedding_dim), dtype='int32')\n",
    "    value_input = tf.keras.Input(shape=(None, max_tokens, embedding_dim), dtype='int32')\n",
    "    x = (query_input, value_input)\n",
    "    return Model(inputs=x, outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1695612134294,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "WpLSon3cNVvc"
   },
   "outputs": [],
   "source": [
    "model = AttentionModel(100, 10, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 922,
     "status": "error",
     "timestamp": 1695612135205,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "CSRhli0ZWFxf",
    "outputId": "0daf1b38-9079-4d5f-f375-f16cb09666bc"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5f15418b3570>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable, layer_range)\u001b[0m\n\u001b[1;32m   3401\u001b[0m         \"\"\"\n\u001b[1;32m   3402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3404\u001b[0m                 \u001b[0;34m\"This model has not yet been built. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m                 \u001b[0;34m\"Build the model first by calling `build()` or by calling \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXOb_IEGqV2p"
   },
   "source": [
    "Oh no! We need to call the model, well that is simple let's simulate 3 sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1695612146664,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "Mtn3d4wwyEGU"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 20\n",
    "max_tokens = 10\n",
    "query = tf.constant(np.random.randint(0, embedding_dim, size=(3,max_tokens)))\n",
    "value = tf.constant(np.random.randint(0, embedding_dim, size=(3,max_tokens)))\n",
    "\n",
    "response = model((query,value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1695612147108,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "8ngnlesuSTyC",
    "outputId": "f6d9c86f-b2f2-4b6f-bfe6-c16c332083ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 100])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1695612147108,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "bZCFervbyf7i",
    "outputId": "c498fccf-7ef4-4c63-c589-68b4cadab9e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  2000      \n",
      "                                                                 \n",
      " additive_attention (Additi  multiple                  20        \n",
      " veAttention)                                                    \n",
      "                                                                 \n",
      " dropout (Dropout)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4120 (16.09 KB)\n",
      "Trainable params: 4120 (16.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1695612147426,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "Gi07wCzxXNt7",
    "outputId": "ac89eb13-ca0a-4510-b94c-908eb45fa2f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7b106007fa00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_graph(max_tokens=max_tokens, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1695612147717,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "X1PW8NYaXOTq",
    "outputId": "57f5f30a-ad91-4ec2-d65b-549f321bd1e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 10, 20, 20   2000      \n",
      "                             )                                   \n",
      "                                                                 \n",
      " additive_attention (Additi  (None, None, 10, 20, 20   20        \n",
      " veAttention)                )                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 10, 20, 20   0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 10, 20, 10   2100      \n",
      "                             0)                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4120 (16.09 KB)\n",
      "Trainable params: 4120 (16.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWQHcNquqfVK"
   },
   "source": [
    "Notice that attention adds very few parameters, adds many knowledge to the following layers, and is paralellizable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5y1okQ9QJ48"
   },
   "source": [
    "## MultiHead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bakdsYuhqogu"
   },
   "source": [
    "Now you are ready to see Multi Head Attention. The idea is quite simple, as in CNNs we had many filters and each convolution checked many different aspects of an image, having many self attentions can check different aspects of our entity, globally. In image it is:\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src='https://www.dropbox.com/s/wjfxpap06viclhv/mha.png?raw=1'  />\n",
    "<figcaption>Attention</figcaption></center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4tqYQY3rPCJ"
   },
   "source": [
    "Each head performs Scaled attention as we did before with the weird formula, and then we concatenate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1695612151363,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "7TqMEi2gQNFZ"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, num_heads, vocab_size, attention_dim, max_tokens, embedding_dim, dropout_rate):\n",
    "    super().__init__()\n",
    "    self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_tokens)\n",
    "\n",
    "    # key_dim stands for size of each attention head for query and key, we can also pass value_key is K!=V\n",
    "    self.attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=attention_dim, dropout=dropout_rate)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "  def call(self, inputs, training=False):\n",
    "\n",
    "    query, value = inputs\n",
    "    # Query embeddings of shape [batch_size, Tq, dimension].\n",
    "    query_embeddings = self.embedding(query)\n",
    "    # Value embeddings of shape [batch_size, Tv, dimension].\n",
    "    value_embeddings = self.embedding(value)\n",
    "    x, weights = self.attention(query_embeddings, value_embeddings, return_attention_scores=True)  # We return the scores to do our plot!\n",
    "    x = self.dense(x, training=training)\n",
    "    return x, weights\n",
    "\n",
    "  def build_graph(self, max_tokens, embedding_dim):\n",
    "    query_input = tf.keras.Input(shape=(max_tokens, embedding_dim), dtype='int32')\n",
    "    value_input = tf.keras.Input(shape=(max_tokens, embedding_dim), dtype='int32')\n",
    "    x = (query_input, value_input)\n",
    "    return Model(inputs=x, outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1695612151364,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "HyWkokOtw6GW"
   },
   "outputs": [],
   "source": [
    "vocab_size=100\n",
    "model = MultiHeadAttentionModel(num_heads=3, vocab_size=vocab_size, attention_dim=2, max_tokens=max_tokens, embedding_dim=embedding_dim, dropout_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1695612152337,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "vXhcalSwxF9a",
    "outputId": "218e9bc6-36c5-4a05-9f60-78a1c74c703e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.functional.Functional at 0x7b105cbb3b80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build_graph(max_tokens=max_tokens, embedding_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1695612152337,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "HW4raKPVxPNj"
   },
   "outputs": [],
   "source": [
    "query = tf.constant(np.random.randint(0,vocab_size, size=(3,max_tokens, 10)))\n",
    "value = tf.constant(np.random.randint(0,vocab_size, size=(3,max_tokens, 10)))\n",
    "\n",
    "response, weights = model((query,value) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1695612152669,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "HelBLsdnxbL7",
    "outputId": "dfa5ec9b-82f9-4efc-956e-874f6fa94c01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 10, 10, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrYWnu1RsQWS"
   },
   "source": [
    "**Can you guess each value in the response.shape where does it come from?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1695612152670,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "OG5X7dchyN4v",
    "outputId": "ead7d2c2-145e-4bb7-8993-0ad98c290e92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 10, 10, 10, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVfmU78bsaIG"
   },
   "source": [
    "**And for the weights??**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1695612153319,
     "user": {
      "displayName": "Axel Sirota",
      "userId": "02089179879199828401"
     },
     "user_tz": 180
    },
    "id": "esLeIv1IyOtf",
    "outputId": "74d825cc-adef-4c3e-e099-2ac97bb4358b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multi_head_attention_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 10, 20, 20)        2000      \n",
      "                                                                 \n",
      " multi_head_attention (Mult  ((None, 10, 20, 20),      518       \n",
      " iHeadAttention)              (None, 3, 10, 20, 10,              \n",
      "                             20))                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10, 20, 100)       2100      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4618 (18.04 KB)\n",
      "Trainable params: 4618 (18.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-KQ5uhrsfmB"
   },
   "source": [
    "Again, notice Attention as complex as multi head attention did not add many params and adds a lot lexical intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3oKCxnNXCot"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPj5ESFtz13HLkVzxJhQqT0",
   "provenance": [
    {
     "file_id": "1I0KA4wCjVa0s9YZsLkAX6JaN-bAdLUlb",
     "timestamp": 1695269238458
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}